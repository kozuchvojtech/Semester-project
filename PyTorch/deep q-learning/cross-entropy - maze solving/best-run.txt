training 1st maze
0: loss=1.369, reward_mean=0.067, reward_bound=0.000, batch=1
1: loss=1.352, reward_mean=0.067, reward_bound=0.000, batch=2
2: loss=1.371, reward_mean=0.067, reward_bound=0.000, batch=3
3: loss=1.374, reward_mean=0.133, reward_bound=0.401, batch=5
4: loss=1.367, reward_mean=-0.067, reward_bound=0.134, batch=5
5: loss=1.352, reward_mean=0.200, reward_bound=0.809, batch=5
6: loss=1.338, reward_mean=0.133, reward_bound=0.834, batch=4
7: loss=1.358, reward_mean=0.000, reward_bound=0.400, batch=5
8: loss=1.317, reward_mean=0.133, reward_bound=0.825, batch=5
9: loss=1.368, reward_mean=0.333, reward_bound=0.868, batch=3
10: loss=1.326, reward_mean=0.067, reward_bound=0.000, batch=4
11: loss=1.346, reward_mean=0.067, reward_bound=0.786, batch=5
12: loss=1.395, reward_mean=0.467, reward_bound=0.886, batch=4
13: loss=1.381, reward_mean=0.000, reward_bound=0.434, batch=5
14: loss=1.364, reward_mean=0.200, reward_bound=0.904, batch=3
15: loss=1.327, reward_mean=0.000, reward_bound=0.000, batch=4
16: loss=1.357, reward_mean=0.400, reward_bound=0.868, batch=4
17: loss=1.356, reward_mean=0.133, reward_bound=0.904, batch=4
18: loss=1.357, reward_mean=0.333, reward_bound=0.913, batch=5
19: loss=1.346, reward_mean=0.067, reward_bound=0.731, batch=5
20: loss=1.319, reward_mean=0.200, reward_bound=0.922, batch=2
21: loss=1.303, reward_mean=0.200, reward_bound=0.851, batch=4
22: loss=1.321, reward_mean=0.067, reward_bound=0.868, batch=4
23: loss=1.319, reward_mean=0.400, reward_bound=0.913, batch=5
24: loss=1.307, reward_mean=0.000, reward_bound=0.231, batch=5
25: loss=1.289, reward_mean=0.333, reward_bound=0.922, batch=3
26: loss=1.281, reward_mean=0.200, reward_bound=0.899, batch=5
27: loss=1.272, reward_mean=0.133, reward_bound=0.827, batch=5
28: loss=1.259, reward_mean=0.333, reward_bound=0.909, batch=5
29: loss=1.248, reward_mean=0.067, reward_bound=0.909, batch=5
30: loss=1.240, reward_mean=0.067, reward_bound=0.922, batch=3
31: loss=1.227, reward_mean=0.333, reward_bound=0.918, batch=5
32: loss=1.220, reward_mean=0.400, reward_bound=0.922, batch=4
33: loss=1.232, reward_mean=0.200, reward_bound=0.860, batch=5
34: loss=1.203, reward_mean=0.200, reward_bound=0.886, batch=4
35: loss=1.214, reward_mean=0.467, reward_bound=1.215, batch=5
36: loss=1.208, reward_mean=0.200, reward_bound=1.015, batch=5
37: loss=1.202, reward_mean=0.200, reward_bound=1.015, batch=5
38: loss=1.196, reward_mean=0.200, reward_bound=1.069, batch=5
39: loss=1.191, reward_mean=0.133, reward_bound=1.055, batch=5
40: loss=1.186, reward_mean=0.467, reward_bound=1.212, batch=5
41: loss=1.254, reward_mean=0.333, reward_bound=1.515, batch=5
42: loss=1.252, reward_mean=0.600, reward_bound=1.515, batch=5
43: loss=1.250, reward_mean=0.333, reward_bound=1.049, batch=5
44: loss=1.247, reward_mean=0.333, reward_bound=1.076, batch=5
45: loss=1.243, reward_mean=0.267, reward_bound=1.386, batch=5
46: loss=1.239, reward_mean=0.600, reward_bound=1.346, batch=5
47: loss=1.234, reward_mean=0.400, reward_bound=1.448, batch=5
48: loss=1.229, reward_mean=0.400, reward_bound=1.036, batch=5
49: loss=1.210, reward_mean=0.467, reward_bound=1.538, batch=4
50: loss=1.223, reward_mean=0.600, reward_bound=1.434, batch=5
51: loss=1.218, reward_mean=0.333, reward_bound=1.455, batch=5
52: loss=1.180, reward_mean=0.600, reward_bound=1.500, batch=5
53: loss=1.183, reward_mean=0.667, reward_bound=1.577, batch=5
54: loss=1.178, reward_mean=0.267, reward_bound=1.065, batch=5
55: loss=1.173, reward_mean=0.800, reward_bound=1.531, batch=5
56: loss=1.168, reward_mean=0.333, reward_bound=1.092, batch=5
57: loss=1.147, reward_mean=0.600, reward_bound=1.610, batch=5
58: loss=1.168, reward_mean=1.000, reward_bound=1.634, batch=3
59: loss=1.134, reward_mean=0.267, reward_bound=0.776, batch=5
60: loss=1.136, reward_mean=0.733, reward_bound=1.406, batch=5
61: loss=1.126, reward_mean=0.800, reward_bound=1.667, batch=4
62: loss=1.142, reward_mean=0.800, reward_bound=1.143, batch=5
63: loss=1.107, reward_mean=0.467, reward_bound=1.361, batch=5
64: loss=1.110, reward_mean=0.867, reward_bound=1.667, batch=4
65: loss=1.124, reward_mean=0.533, reward_bound=1.216, batch=5
66: loss=1.120, reward_mean=0.467, reward_bound=1.283, batch=5
67: loss=1.048, reward_mean=1.533, reward_bound=1.894, batch=4
68: loss=1.035, reward_mean=0.733, reward_bound=1.443, batch=5
69: loss=1.032, reward_mean=0.333, reward_bound=1.169, batch=5
70: loss=1.065, reward_mean=1.000, reward_bound=1.975, batch=5
71: loss=1.061, reward_mean=0.733, reward_bound=1.390, batch=5
72: loss=1.056, reward_mean=0.667, reward_bound=1.446, batch=5
73: loss=1.013, reward_mean=0.733, reward_bound=2.023, batch=5
74: loss=0.917, reward_mean=1.200, reward_bound=2.169, batch=5
75: loss=0.910, reward_mean=0.800, reward_bound=1.320, batch=5
76: loss=0.903, reward_mean=0.933, reward_bound=2.367, batch=5
77: loss=0.877, reward_mean=1.200, reward_bound=2.513, batch=4
78: loss=0.937, reward_mean=0.867, reward_bound=1.178, batch=5
79: loss=0.858, reward_mean=0.600, reward_bound=1.390, batch=4
80: loss=0.934, reward_mean=1.067, reward_bound=1.823, batch=5
81: loss=0.831, reward_mean=0.800, reward_bound=2.351, batch=5
82: loss=0.789, reward_mean=1.000, reward_bound=2.725, batch=3
83: loss=0.917, reward_mean=1.400, reward_bound=2.017, batch=5
84: loss=0.909, reward_mean=0.867, reward_bound=1.687, batch=5
85: loss=0.850, reward_mean=1.400, reward_bound=2.298, batch=5
86: loss=0.766, reward_mean=2.267, reward_bound=2.644, batch=5
training 2nd maze
0: loss=1.066, reward_mean=-0.067, reward_bound=0.362, batch=4
1: loss=1.068, reward_mean=0.400, reward_bound=0.777, batch=5
2: loss=1.037, reward_mean=0.600, reward_bound=0.939, batch=5
3: loss=1.034, reward_mean=-0.267, reward_bound=0.845, batch=5
4: loss=1.014, reward_mean=-0.200, reward_bound=1.032, batch=5
5: loss=1.015, reward_mean=0.000, reward_bound=1.183, batch=4
6: loss=1.006, reward_mean=-0.133, reward_bound=0.962, batch=5
7: loss=1.001, reward_mean=0.400, reward_bound=1.201, batch=5
8: loss=0.968, reward_mean=0.200, reward_bound=1.257, batch=5
9: loss=0.961, reward_mean=0.600, reward_bound=1.316, batch=5
10: loss=0.895, reward_mean=0.333, reward_bound=1.350, batch=5
11: loss=0.893, reward_mean=0.467, reward_bound=1.405, batch=5
12: loss=0.890, reward_mean=0.200, reward_bound=1.448, batch=5
13: loss=0.882, reward_mean=1.000, reward_bound=1.485, batch=5
14: loss=0.892, reward_mean=0.800, reward_bound=1.525, batch=5
15: loss=0.849, reward_mean=0.667, reward_bound=1.588, batch=5
16: loss=0.886, reward_mean=0.667, reward_bound=1.636, batch=3
17: loss=0.798, reward_mean=1.133, reward_bound=1.640, batch=5
18: loss=0.801, reward_mean=1.200, reward_bound=1.731, batch=5
19: loss=0.797, reward_mean=0.133, reward_bound=1.583, batch=5
20: loss=0.792, reward_mean=0.600, reward_bound=1.631, batch=5
21: loss=0.822, reward_mean=1.267, reward_bound=1.810, batch=4
22: loss=0.777, reward_mean=1.000, reward_bound=1.449, batch=5
23: loss=0.758, reward_mean=0.200, reward_bound=1.583, batch=5
24: loss=0.790, reward_mean=1.067, reward_bound=1.820, batch=5
25: loss=0.783, reward_mean=1.067, reward_bound=1.505, batch=5
26: loss=0.776, reward_mean=0.933, reward_bound=1.766, batch=5
27: loss=0.769, reward_mean=1.733, reward_bound=1.820, batch=5
28: loss=0.868, reward_mean=1.467, reward_bound=1.847, batch=4
29: loss=0.851, reward_mean=0.667, reward_bound=1.611, batch=5
30: loss=0.796, reward_mean=1.867, reward_bound=1.783, batch=5
31: loss=0.789, reward_mean=1.400, reward_bound=1.757, batch=5
32: loss=0.829, reward_mean=1.067, reward_bound=1.810, batch=4
33: loss=0.877, reward_mean=1.000, reward_bound=1.797, batch=5
34: loss=0.758, reward_mean=0.333, reward_bound=1.826, batch=5
35: loss=0.780, reward_mean=1.600, reward_bound=1.879, batch=5
36: loss=0.770, reward_mean=1.333, reward_bound=1.907, batch=5
37: loss=0.761, reward_mean=0.600, reward_bound=1.879, batch=5
38: loss=0.752, reward_mean=0.733, reward_bound=1.720, batch=5
39: loss=0.673, reward_mean=1.067, reward_bound=1.972, batch=4
40: loss=0.726, reward_mean=0.800, reward_bound=1.829, batch=5
41: loss=0.719, reward_mean=0.800, reward_bound=1.665, batch=5
42: loss=0.681, reward_mean=1.200, reward_bound=1.985, batch=5
43: loss=0.675, reward_mean=1.133, reward_bound=1.993, batch=5
44: loss=0.669, reward_mean=1.133, reward_bound=1.644, batch=5
45: loss=0.641, reward_mean=1.600, reward_bound=2.062, batch=5
46: loss=0.636, reward_mean=0.933, reward_bound=2.062, batch=5
47: loss=0.611, reward_mean=0.800, reward_bound=2.085, batch=4
48: loss=0.591, reward_mean=1.133, reward_bound=2.128, batch=5
49: loss=0.586, reward_mean=0.667, reward_bound=1.928, batch=5
50: loss=0.581, reward_mean=1.200, reward_bound=1.901, batch=5
51: loss=0.575, reward_mean=0.600, reward_bound=1.698, batch=5
52: loss=0.570, reward_mean=1.133, reward_bound=1.907, batch=5
53: loss=0.564, reward_mean=1.200, reward_bound=1.821, batch=5
54: loss=0.558, reward_mean=0.867, reward_bound=1.901, batch=5
55: loss=0.674, reward_mean=1.400, reward_bound=2.171, batch=3
56: loss=0.663, reward_mean=1.733, reward_bound=1.984, batch=5
57: loss=0.661, reward_mean=1.467, reward_bound=2.160, batch=5
58: loss=0.629, reward_mean=1.867, reward_bound=2.226, batch=2
59: loss=0.617, reward_mean=1.800, reward_bound=1.885, batch=4
60: loss=0.626, reward_mean=1.000, reward_bound=1.921, batch=5
61: loss=0.622, reward_mean=1.467, reward_bound=2.015, batch=5
62: loss=0.586, reward_mean=1.267, reward_bound=2.226, batch=4
63: loss=0.552, reward_mean=1.800, reward_bound=2.318, batch=3
64: loss=0.608, reward_mean=1.400, reward_bound=2.226, batch=4
65: loss=0.601, reward_mean=2.400, reward_bound=2.228, batch=5
training 3rd maze
0: loss=0.761, reward_mean=0.800, reward_bound=0.886, batch=4
1: loss=0.733, reward_mean=1.200, reward_bound=1.580, batch=5
2: loss=0.686, reward_mean=0.800, reward_bound=1.618, batch=5
3: loss=0.716, reward_mean=0.000, reward_bound=1.664, batch=5
4: loss=0.559, reward_mean=-0.467, reward_bound=1.747, batch=3
5: loss=0.633, reward_mean=-0.467, reward_bound=0.620, batch=5
6: loss=0.662, reward_mean=-0.067, reward_bound=1.324, batch=5
7: loss=0.588, reward_mean=0.667, reward_bound=1.914, batch=5
8: loss=0.650, reward_mean=0.533, reward_bound=1.993, batch=5
9: loss=0.641, reward_mean=0.867, reward_bound=1.934, batch=5
10: loss=0.498, reward_mean=1.467, reward_bound=2.160, batch=5
11: loss=0.507, reward_mean=0.933, reward_bound=2.249, batch=5
12: loss=0.501, reward_mean=0.867, reward_bound=2.249, batch=5
13: loss=0.497, reward_mean=0.933, reward_bound=2.318, batch=4
14: loss=0.539, reward_mean=0.400, reward_bound=2.115, batch=5
15: loss=0.490, reward_mean=0.867, reward_bound=2.226, batch=4
16: loss=0.508, reward_mean=0.867, reward_bound=2.012, batch=5
17: loss=0.464, reward_mean=1.000, reward_bound=2.207, batch=5
18: loss=0.365, reward_mean=1.000, reward_bound=2.414, batch=1
19: loss=0.466, reward_mean=2.600, reward_bound=2.183, batch=4
testing
[[1, 0, 0, 1, 0, 1, 1, 0], [1, 0, 0, 0, 0, 1, 1, 0], [1, 0, 0, 0, 0, 1, 1, 0], [1, 0, 0, 0, 0, 1, 1, 0], [1, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 1, 0, 0, 1, 0], [0, 0, 0, 1, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 1, 1, 0], [0, 0, 1, 0, 0, 1, 1, 0], [0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 1, 0, 0, 1, 0], [0, 0, 0, 1, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0]]